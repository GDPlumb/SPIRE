{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "\n",
    "from Base import *\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/gregory/Desktop/CounterVision/Code\")\n",
    "from Checker import Checker\n",
    "from Core import acc, prob\n",
    "from Heuristics import *\n",
    "from Learner import Learner\n",
    "from Search import search\n",
    "from Train import train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our datasets\n",
    "\n",
    "p = 1.0\n",
    "\n",
    "d = 6\n",
    "n = 1000\n",
    "\n",
    "X = np.zeros((n, d))\n",
    "y = np.zeros((n, 1))\n",
    "for i in range(n):\n",
    "    X[i, :], y[i] = sample_1(p = p)\n",
    "    \n",
    "X = np.float32(X)\n",
    "y = np.float32(y)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5)\n",
    "\n",
    "X_neutral = np.zeros((100, d))\n",
    "y_neutral = np.zeros((100, 1))\n",
    "for i in range(100):\n",
    "    X_neutral[i, :], y_neutral[i] = sample_uniform()\n",
    "    \n",
    "X_neutral = np.float32(X_neutral)\n",
    "y_neutral = np.float32(y_neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               700       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 10,901\n",
      "Trainable params: 10,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test Acc:  1.0\n",
      "Neutral Acc:  0.8\n"
     ]
    }
   ],
   "source": [
    "# Train a model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "          tf.keras.layers.InputLayer(input_shape=(6)),\n",
    "          tf.keras.layers.Dense(100, activation='relu'),\n",
    "          tf.keras.layers.Dense(100, activation='relu'),\n",
    "          tf.keras.layers.Dense(1)\n",
    "          ])\n",
    "\n",
    "def loss(model, inputs, labels):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = model(inputs), labels = labels))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train(model, loss, X_train, y_train, X_val, y_val, \"Tabular/model\", learning_rate = 0.01)\n",
    "    \n",
    "print(\"Test Acc: \", acc(model, X_test, y_test))\n",
    "print(\"Neutral Acc: \", acc(model, X_neutral, y_neutral))\n",
    "#print(model.get_layer(\"dense\").get_weights())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching feature  0\n",
      "\n",
      "Heuristic:  [0, 0]\n",
      "Success on Train:  192.0\n",
      "Counts:  555 558 184 192\n",
      "Train Metrics:  [0.99462366 0.95833333]\n",
      "Success on Val:  35.0\n",
      "Counts:  89 90 30 35\n",
      "Validation Metrics:  [0.98888889 0.85714286]\n",
      "Accepted\n",
      "\n",
      "\n",
      "Heuristic:  [0, 1]\n",
      "Success on Train:  188.0\n",
      "Counts:  557 562 185 188\n",
      "Train Metrics:  [0.9911032  0.98404255]\n",
      "Success on Val:  51.0\n",
      "Counts:  74 74 49 51\n",
      "Validation Metrics:  [1.         0.96078431]\n",
      "Accepted\n",
      "\n",
      "\n",
      "Searching feature  1\n",
      "\n",
      "Heuristic:  [[ 0.   -0.05  0.    0.    0.    0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.   0.05 0.   0.   0.   0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[ 0.  -0.1  0.   0.   0.   0. ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.  0.1 0.  0.  0.  0. ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[ 0.   -0.25  0.    0.    0.    0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.   0.25 0.   0.   0.   0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Searching feature  2\n",
      "\n",
      "Heuristic:  [[ 0.    0.   -0.05  0.    0.    0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.   0.   0.05 0.   0.   0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[ 0.   0.  -0.1  0.   0.   0. ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.  0.  0.1 0.  0.  0. ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[ 0.    0.   -0.25  0.    0.    0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.   0.   0.25 0.   0.   0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Searching feature  3\n",
      "\n",
      "Heuristic:  [3, 0]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [3, 1]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Searching feature  4\n",
      "\n",
      "Heuristic:  [[ 0.    0.    0.    0.   -0.05  0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.   0.   0.   0.   0.05 0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[ 0.   0.   0.   0.  -0.1  0. ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.  0.  0.  0.  0.1 0. ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[ 0.    0.    0.    0.   -0.25  0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.   0.   0.   0.   0.25 0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Searching feature  5\n",
      "\n",
      "Heuristic:  [5, 0]\n",
      "Success on Train:  167.0\n",
      "Counts:  580 583 164 167\n",
      "Train Metrics:  [0.9948542  0.98203593]\n",
      "Success on Val:  28.0\n",
      "Counts:  95 97 25 28\n",
      "Validation Metrics:  [0.97938144 0.89285714]\n",
      "Accepted\n",
      "\n",
      "\n",
      "Heuristic:  [5, 1]\n",
      "Success on Train:  157.0\n",
      "Counts:  592 593 150 157\n",
      "Train Metrics:  [0.99831366 0.95541401]\n",
      "Success on Val:  43.0\n",
      "Counts:  79 82 42 43\n",
      "Validation Metrics:  [0.96341463 0.97674419]\n",
      "Accepted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_train = prob(model, X_train)\n",
    "y_hat_val = prob(model, X_val)\n",
    "\n",
    "checker = Checker(\"label\")\n",
    "learner = Learner(KNeighborsClassifier)\n",
    "perturber_con = ContinuousPerturber()\n",
    "perturber_cat = CategoricalPerturber()\n",
    "\n",
    "# Search the continuous features\n",
    "for index in range(6):\n",
    "    \n",
    "    print(\"\\nSearching feature \", index)\n",
    "    \n",
    "    if index in [1, 2, 4]:\n",
    "        heuristics = []\n",
    "        for value in [-0.05, 0.05, -0.1, 0.1, -0.25, 0.25]:\n",
    "            pert = np.zeros((1, d))\n",
    "            pert[0, index] = value\n",
    "            heuristics.append(pert)\n",
    "        perturber = perturber_con\n",
    "    \n",
    "    if index in [0, 3, 5]:\n",
    "        heuristics = []\n",
    "        heuristics.append([index, 0])\n",
    "        heuristics.append([index, 1])\n",
    "        perturber = perturber_cat\n",
    "        \n",
    "    out = search(model, X_train, y_hat_train, heuristics, perturber, checker, learner, use_val = True, X_val = X_val, y_val = y_hat_val, use_acc = False, min_explainability = 0.8, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New training size:  1074\n",
      "Test Acc:  1.0\n",
      "Neutral Acc:  1.0\n",
      "\n",
      "Heuristic:  [5, 0]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [5, 1]\n",
      "Success on Train:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Selective data augmentation\n",
    "\n",
    "model.load_weights(\"Tabular/model\")\n",
    "\n",
    "def augment(model, perturber, h, X, y):\n",
    "    X_pert, y_pert = perturber.apply(model, X, h)\n",
    "    s_pert = checker.check(y, y_pert)\n",
    "    indices = np.where(s_pert == 1)[0]\n",
    "    return X_pert[indices, :], y[indices]\n",
    "\n",
    "perturber = perturber_cat\n",
    "\n",
    "X_train_0, y_train_0 = augment(model, perturber, [5, 0], X_train, y_train)\n",
    "X_train_1, y_train_1 = augment(model, perturber, [5, 1], X_train, y_train)\n",
    "\n",
    "X_val_0, y_val_0 = augment(model, perturber, [5, 0], X_val, y_val)\n",
    "X_val_1, y_val_1 = augment(model, perturber, [5, 1], X_val, y_val)\n",
    "\n",
    "X_train_aug = np.vstack((X_train, X_train_0, X_train_1))\n",
    "y_train_aug = np.vstack((y_train, y_train_0, y_train_1))\n",
    "\n",
    "print(\"New training size: \", X_train_aug.shape[0])\n",
    "\n",
    "X_val_aug = np.vstack((X_val, X_val_0, X_val_1))\n",
    "y_val_aug = np.vstack((y_val, y_val_0, y_val_1))\n",
    "    \n",
    "\n",
    "train(model, loss, X_train_aug, y_train_aug, X_val_aug, y_val_aug, \"Tabular/model_aug\", learning_rate = 0.01, stopping_tol = 0.00001)\n",
    "\n",
    "print(\"Test Acc: \", acc(model, X_test, y_test))\n",
    "print(\"Neutral Acc: \", acc(model, X_neutral, y_neutral))\n",
    "#print(model.get_layer(\"dense\").get_weights())\n",
    "\n",
    "y_hat_train = prob(model, X_train)\n",
    "y_hat_val = prob(model, X_val)\n",
    "\n",
    "heuristics = []\n",
    "heuristics.append([5, 0])\n",
    "heuristics.append([5, 1])\n",
    "perturber = CategoricalPerturber()\n",
    "\n",
    "out = search(model, X_train, y_hat_train, heuristics, perturber, checker, learner, use_val = True, X_val = X_val, y_val = y_hat_val, use_acc = False, min_explainability = 0.8, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:countervision]",
   "language": "python",
   "name": "conda-env-countervision-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

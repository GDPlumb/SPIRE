{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "\n",
    "from Base import *\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/gregory/Desktop/CounterVision/Code\")\n",
    "from Checker import Checker\n",
    "from Core import acc, prob\n",
    "from Heuristics import *\n",
    "from Learner import Learner\n",
    "from Search import search\n",
    "from Train import train\n",
    "sys.path.insert(0, \"/home/gregory/Desktop/EIE/SimpleData\")\n",
    "from SimpleData import vec2im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our datasets\n",
    "\n",
    "p = 1.0\n",
    "\n",
    "d = 6\n",
    "n = 1000\n",
    "\n",
    "rep = np.zeros((n, d))\n",
    "X = np.zeros((n, 64, 64, 3))\n",
    "y = np.zeros((n, 1))\n",
    "for i in range(n):\n",
    "    rep[i, :], y[i] = sample_1(p = p)\n",
    "    X[i, :] = vec2im(rep[i, :])\n",
    "    \n",
    "X = np.float32(X) / 255\n",
    "y = np.float32(y)\n",
    "    \n",
    "rep_train, rep_test, X_train, X_test, y_train, y_test = train_test_split(rep, X, y, test_size = 0.25)\n",
    "rep_val, rep_test, X_val, X_test, y_val, y_test = train_test_split(rep_test, X_test, y_test, test_size = 0.5)\n",
    "\n",
    "\n",
    "rep_neutral = np.zeros((100, d))\n",
    "X_neutral = np.zeros((100, 64, 64, 3))\n",
    "y_neutral = np.zeros((100, 1))\n",
    "for i in range(100):\n",
    "    rep_neutral[i, :], y_neutral[i] = sample_uniform()\n",
    "    X_neutral[i, :] = vec2im(rep_neutral[i, :])\n",
    "    \n",
    "X_neutral = np.float32(X_neutral) / 255\n",
    "y_neutral = np.float32(y_neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 65,825\n",
      "Trainable params: 65,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test Acc:  1.0\n",
      "Neutral Acc:  0.57\n"
     ]
    }
   ],
   "source": [
    "# Train a model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "          tf.keras.layers.InputLayer(input_shape=(64,64,3)),\n",
    "          tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "          tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "          tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "          tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "          tf.keras.layers.Flatten(),\n",
    "          tf.keras.layers.Dense(1)\n",
    "          ])\n",
    "\n",
    "def loss(model, inputs, labels):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = model(inputs), labels = labels))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train(model, loss, X_train, y_train, X_val, y_val, \"Image/model\")\n",
    "    \n",
    "print(\"Test Acc: \", acc(model, X_test, y_test))\n",
    "print(\"Neutral Acc: \", acc(model, X_neutral, y_neutral))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on reconstructed test set:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained encoders and decoders for this dataset\n",
    "\n",
    "encoder = tf.keras.Sequential([\n",
    "          tf.keras.layers.InputLayer(input_shape=(64, 64, 3)),\n",
    "          tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "          tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "          tf.keras.layers.Flatten(),\n",
    "          tf.keras.layers.Dense(6)\n",
    "          ])\n",
    "\n",
    "encoder.load_weights(\"/home/gregory/Desktop/EIE/SimpleData/1-Encoder/model\")\n",
    "\n",
    "decoder = tf.keras.Sequential(\n",
    "        [\n",
    "          tf.keras.layers.InputLayer(input_shape=(6)),\n",
    "          tf.keras.layers.Dense(units=8*8*64, activation=tf.nn.relu),\n",
    "          tf.keras.layers.Reshape(target_shape=(8, 8, 64)),\n",
    "          tf.keras.layers.Conv2DTranspose(\n",
    "              filters=64,\n",
    "              kernel_size=3,\n",
    "              strides=(2, 2),\n",
    "              padding=\"SAME\",\n",
    "              activation='relu'),\n",
    "          tf.keras.layers.Conv2DTranspose(\n",
    "              filters=32,\n",
    "              kernel_size=3,\n",
    "              strides=(2, 2),\n",
    "              padding=\"SAME\",\n",
    "              activation='relu'),\n",
    "          tf.keras.layers.Conv2DTranspose(\n",
    "              filters=32,\n",
    "              kernel_size=3,\n",
    "              strides=(2, 2),\n",
    "              padding=\"SAME\",\n",
    "              activation='relu'),\n",
    "          tf.keras.layers.Conv2DTranspose(\n",
    "              filters=3, kernel_size=3, strides=(1, 1), padding=\"SAME\", activation = \"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "decoder.load_weights(\"/home/gregory/Desktop/EIE/SimpleData/1-Decoder/model\")\n",
    "\n",
    "rep_test_hat = encoder(X_test).numpy()\n",
    "X_test_hat = decoder(rep_test_hat).numpy()\n",
    "print(\"Accuracy on reconstructed test set: \", acc(model, X_test_hat, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching feature  0\n",
      "\n",
      "Heuristic:  [0, 0]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [0, 1]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Searching feature  1\n",
      "\n",
      "Heuristic:  [[ 0.   -0.05  0.    0.    0.    0.  ]]\n",
      "WARNING:tensorflow:Layer dense_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.   0.05 0.   0.   0.   0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[ 0.  -0.1  0.   0.   0.   0. ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.  0.1 0.  0.  0.  0. ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[ 0.   -0.25  0.    0.    0.    0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.   0.25 0.   0.   0.   0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Searching feature  2\n",
      "\n",
      "Heuristic:  [[ 0.    0.   -0.05  0.    0.    0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.   0.   0.05 0.   0.   0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[ 0.   0.  -0.1  0.   0.   0. ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.  0.  0.1 0.  0.  0. ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[ 0.    0.   -0.25  0.    0.    0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.   0.   0.25 0.   0.   0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Searching feature  3\n",
      "\n",
      "Heuristic:  [3, 0]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [3, 1]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Searching feature  4\n",
      "\n",
      "Heuristic:  [[ 0.    0.    0.    0.   -0.05  0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.   0.   0.   0.   0.05 0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[ 0.   0.   0.   0.  -0.1  0. ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.  0.  0.  0.  0.1 0. ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[ 0.    0.    0.    0.   -0.25  0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.   0.   0.   0.   0.25 0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Searching feature  5\n",
      "\n",
      "Heuristic:  [5, 0]\n",
      "Success on Train:  367.0\n",
      "Counts:  383 383 367 367\n",
      "Train Metrics:  [1. 1.]\n",
      "Success on Val:  55.0\n",
      "Counts:  70 70 55 55\n",
      "Validation Metrics:  [1. 1.]\n",
      "Accepted\n",
      "\n",
      "\n",
      "Heuristic:  [5, 1]\n",
      "Success on Train:  383.0\n",
      "Counts:  367 367 383 383\n",
      "Train Metrics:  [1. 1.]\n",
      "Success on Val:  70.0\n",
      "Counts:  55 55 70 70\n",
      "Validation Metrics:  [1. 1.]\n",
      "Accepted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_train = prob(model, X_train)\n",
    "y_hat_val = prob(model, X_val)\n",
    "\n",
    "checker = Checker(\"label\")\n",
    "learner = Learner(KNeighborsClassifier, encoder)\n",
    "perturber_con = ContinuousPerturber(encoder = encoder, decoder = decoder)\n",
    "perturber_cat = CategoricalPerturber(encoder = encoder, decoder = decoder)\n",
    "\n",
    "# Search the continuous features\n",
    "for index in range(6):\n",
    "    \n",
    "    print(\"\\nSearching feature \", index)\n",
    "    \n",
    "    if index in [1, 2, 4]:\n",
    "        heuristics = []\n",
    "        for value in [-0.05, 0.05, -0.1, 0.1, -0.25, 0.25]:\n",
    "            pert = np.zeros((1, d))\n",
    "            pert[0, index] = value\n",
    "            heuristics.append(pert)\n",
    "        perturber = perturber_con\n",
    "    \n",
    "    if index in [0, 3, 5]:\n",
    "        heuristics = []\n",
    "        heuristics.append([index, 0])\n",
    "        heuristics.append([index, 1])\n",
    "        perturber = perturber_cat\n",
    "        \n",
    "    out = search(model, X_train, y_hat_train, heuristics, perturber, checker, learner, use_val = True, X_val = X_val, y_val = y_hat_val, use_acc = False, min_explainability = 0.8, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New training size:  1500\n",
      "Test Acc:  1.0\n",
      "Neutral Acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Selective data augmentation\n",
    "\n",
    "model.load_weights(\"Image/model\")\n",
    "\n",
    "def augment(model, perturber, h, X, y):\n",
    "    X_pert, y_pert = perturber.apply(model, X, h)\n",
    "    s_pert = checker.check(y, y_pert)\n",
    "    indices = np.where(s_pert == 1)[0]\n",
    "    return X_pert[indices, :], y[indices]\n",
    "\n",
    "perturber = perturber_cat\n",
    "\n",
    "X_train_0, y_train_0 = augment(model, perturber, [5, 0], X_train, y_train)\n",
    "X_train_1, y_train_1 = augment(model, perturber, [5, 1], X_train, y_train)\n",
    "\n",
    "X_val_0, y_val_0 = augment(model, perturber, [5, 0], X_val, y_val)\n",
    "X_val_1, y_val_1 = augment(model, perturber, [5, 1], X_val, y_val)\n",
    "\n",
    "X_train_aug = np.vstack((X_train, X_train_0, X_train_1))\n",
    "y_train_aug = np.vstack((y_train, y_train_0, y_train_1))\n",
    "\n",
    "print(\"New training size: \", X_train_aug.shape[0])\n",
    "\n",
    "X_val_aug = np.vstack((X_val, X_val_0, X_val_1))\n",
    "y_val_aug = np.vstack((y_val, y_val_0, y_val_1))\n",
    "\n",
    "\n",
    "train(model, loss, X_train_aug, y_train_aug, X_val_aug, y_val_aug, \"Image/model_aug\", stopping_tol = 0.00001)\n",
    "\n",
    "print(\"Test Acc: \", acc(model, X_test, y_test))\n",
    "print(\"Neutral Acc: \", acc(model, X_neutral, y_neutral))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching feature  0\n",
      "\n",
      "Heuristic:  [0, 0]\n",
      "Success on Train:  367.0\n",
      "Counts:  383 383 367 367\n",
      "Train Metrics:  [1. 1.]\n",
      "Success on Val:  55.0\n",
      "Counts:  70 70 55 55\n",
      "Validation Metrics:  [1. 1.]\n",
      "Accepted\n",
      "\n",
      "\n",
      "Heuristic:  [0, 1]\n",
      "Success on Train:  383.0\n",
      "Counts:  367 367 383 383\n",
      "Train Metrics:  [1. 1.]\n",
      "Success on Val:  70.0\n",
      "Counts:  55 55 70 70\n",
      "Validation Metrics:  [1. 1.]\n",
      "Accepted\n",
      "\n",
      "\n",
      "Searching feature  1\n",
      "\n",
      "Heuristic:  [[ 0.   -0.05  0.    0.    0.    0.  ]]\n",
      "Success on Train:  1.0\n",
      "Counts:  749 749 0 1\n",
      "Train Metrics:  [1. 0.]\n",
      "Rejected\n",
      "\n",
      "\n",
      "Heuristic:  [[0.   0.05 0.   0.   0.   0.  ]]\n",
      "Success on Train:  1.0\n",
      "Counts:  749 749 0 1\n",
      "Train Metrics:  [1. 0.]\n",
      "Rejected\n",
      "\n",
      "\n",
      "Heuristic:  [[ 0.  -0.1  0.   0.   0.   0. ]]\n",
      "Success on Train:  2.0\n",
      "Counts:  748 748 0 2\n",
      "Train Metrics:  [1. 0.]\n",
      "Rejected\n",
      "\n",
      "\n",
      "Heuristic:  [[0.  0.1 0.  0.  0.  0. ]]\n",
      "Success on Train:  2.0\n",
      "Counts:  748 748 0 2\n",
      "Train Metrics:  [1. 0.]\n",
      "Rejected\n",
      "\n",
      "\n",
      "Heuristic:  [[ 0.   -0.25  0.    0.    0.    0.  ]]\n",
      "Success on Train:  49.0\n",
      "Counts:  698 701 33 49\n",
      "Train Metrics:  [0.9957204  0.67346939]\n",
      "Rejected\n",
      "\n",
      "\n",
      "Heuristic:  [[0.   0.25 0.   0.   0.   0.  ]]\n",
      "Success on Train:  19.0\n",
      "Counts:  731 731 1 19\n",
      "Train Metrics:  [1.         0.05263158]\n",
      "Rejected\n",
      "\n",
      "\n",
      "Searching feature  2\n",
      "\n",
      "Heuristic:  [[ 0.    0.   -0.05  0.    0.    0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.   0.   0.05 0.   0.   0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[ 0.   0.  -0.1  0.   0.   0. ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.  0.  0.1 0.  0.  0. ]]\n",
      "Success on Train:  8.0\n",
      "Counts:  742 742 1 8\n",
      "Train Metrics:  [1.    0.125]\n",
      "Rejected\n",
      "\n",
      "\n",
      "Heuristic:  [[ 0.    0.   -0.25  0.    0.    0.  ]]\n",
      "Success on Train:  40.0\n",
      "Counts:  708 710 22 40\n",
      "Train Metrics:  [0.9971831 0.55     ]\n",
      "Rejected\n",
      "\n",
      "\n",
      "Heuristic:  [[0.   0.   0.25 0.   0.   0.  ]]\n",
      "Success on Train:  93.0\n",
      "Counts:  649 657 69 93\n",
      "Train Metrics:  [0.98782344 0.74193548]\n",
      "Rejected\n",
      "\n",
      "\n",
      "Searching feature  3\n",
      "\n",
      "Heuristic:  [3, 0]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [3, 1]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Searching feature  4\n",
      "\n",
      "Heuristic:  [[ 0.    0.    0.    0.   -0.05  0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.   0.   0.   0.   0.05 0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[ 0.   0.   0.   0.  -0.1  0. ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.  0.  0.  0.  0.1 0. ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[ 0.    0.    0.    0.   -0.25  0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [[0.   0.   0.   0.   0.25 0.  ]]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Searching feature  5\n",
      "\n",
      "Heuristic:  [5, 0]\n",
      "Success on Train:  0.0\n",
      "\n",
      "Heuristic:  [5, 1]\n",
      "Success on Train:  0.0\n"
     ]
    }
   ],
   "source": [
    "y_hat_train = prob(model, X_train)\n",
    "y_hat_val = prob(model, X_val)\n",
    "\n",
    "# Search the continuous features\n",
    "for index in range(6):\n",
    "    \n",
    "    print(\"\\nSearching feature \", index)\n",
    "    \n",
    "    if index in [1, 2, 4]:\n",
    "        heuristics = []\n",
    "        for value in [-0.05, 0.05, -0.1, 0.1, -0.25, 0.25]:\n",
    "            pert = np.zeros((1, d))\n",
    "            pert[0, index] = value\n",
    "            heuristics.append(pert)\n",
    "        perturber = perturber_con\n",
    "    \n",
    "    if index in [0, 3, 5]:\n",
    "        heuristics = []\n",
    "        heuristics.append([index, 0])\n",
    "        heuristics.append([index, 1])\n",
    "        perturber = perturber_cat\n",
    "        \n",
    "    out = search(model, X_train, y_hat_train, heuristics, perturber, checker, learner, use_val = True, X_val = X_val, y_val = y_hat_val, use_acc = False, min_explainability = 0.8, verbose = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:countervision]",
   "language": "python",
   "name": "conda-env-countervision-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

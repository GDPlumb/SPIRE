{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from Config import get_data_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_maps(mode, verbose = False):\n",
    "    \n",
    "    if mode == 'train':\n",
    "        threshold = 1000\n",
    "    else:\n",
    "        threshold = 20\n",
    "    \n",
    "    coco = COCO('/home/gregory/Datasets/COCO/annotations/instances_{}2017.json'.format(mode))\n",
    "    captions = COCO('/home/gregory/Datasets/COCO/annotations/captions_{}2017.json'.format(mode))\n",
    "    \n",
    "    # Get the objects associated with each image\n",
    "    id2objs = {}\n",
    "\n",
    "    cats = {x['id']: x['name'] for x in coco.loadCats(coco.getCatIds())}\n",
    "\n",
    "    for img_id, img_obj in coco.anns.items():\n",
    "        i = img_obj['image_id']\n",
    "        o = cats[img_obj['category_id']]\n",
    "\n",
    "        if i not in id2objs:\n",
    "            id2objs[i] = [o]\n",
    "        elif o not in id2objs[i]: # We don't care about how many of each object there are\n",
    "            id2objs[i].append(o)\n",
    "            \n",
    "    # Get the words associated with each image via its caption\n",
    "    id2words = {}\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))  \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "    for img_id, img_obj in captions.anns.items():\n",
    "        i = img_obj['image_id']\n",
    "        c = img_obj['caption']\n",
    "\n",
    "        c = c.lower()\n",
    "        words = tokenizer.tokenize(c)  \n",
    "        words = [w for w in words if not w in stop_words]  \n",
    "\n",
    "        if i not in id2words:\n",
    "            id2words[i] = []\n",
    "\n",
    "        for w in words:\n",
    "            if w not in id2words[i]:\n",
    "                id2words[i].append(w)\n",
    "            \n",
    "    # Make sure that both of those mappings have the same keys\n",
    "    k1 = [key for key in id2objs]\n",
    "    k2 = [key for key in id2words]\n",
    "\n",
    "    just_obj = np.setdiff1d(k1, k2)\n",
    "    just_cap = np.setdiff1d(k2, k1)\n",
    "\n",
    "    for key in just_obj:\n",
    "        del id2objs[key]\n",
    "\n",
    "    for key in just_cap:\n",
    "        del id2words[key] \n",
    "    \n",
    "    # Get a list of all of the words used in the caption and their counts\n",
    "    word2count = {}\n",
    "    for i in id2words.keys():\n",
    "        words = id2words[i]\n",
    "        for w in words:\n",
    "            if w not in word2count:\n",
    "                word2count[w] = 0\n",
    "            word2count[w] += 1\n",
    "            \n",
    "    # Find the most common words\n",
    "    common_words = []\n",
    "    for w in word2count.keys():\n",
    "        if word2count[w] >= threshold:\n",
    "            common_words.append(w)  \n",
    "            \n",
    "    if verbose:\n",
    "        print(common_words)\n",
    "            \n",
    "    # Map the common words to images\n",
    "    word2ids = {}\n",
    "    for word in common_words:\n",
    "        word2ids[word] = []\n",
    "        for img_id in id2words.keys():\n",
    "            if word in id2words[img_id]:\n",
    "                word2ids[word].append(img_id)\n",
    "                \n",
    "    return id2objs, id2words, word2ids\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=11.85s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.70s)\n",
      "creating index...\n",
      "index created!\n",
      "['bicycle', 'clock', 'front', 'bike', 'black', 'metal', 'inside', 'room', 'blue', 'walls', 'white', 'sink', 'door', 'small', 'bathroom', 'wall', 'boat', 'painted', 'baby', 'car', 'parked', 'behind', 'two', 'cars', 'sidewalk', 'street', 'city', 'bench', 'parking', 'along', 'couple', 'busy', 'large', 'passenger', 'airplane', 'flying', 'air', 'plane', 'taking', 'cloudy', 'sky', 'red', 'toilet', 'full', 'little', 'decorated', 'many', 'colorful', 'long', 'empty', 'home', 'kitchen', 'picture', 'looking', 'area', 'refrigerator', 'gray', 'stove', 'counter', 'various', 'items', 'cabinets', 'several', 'across', 'open', 'box', 'four', 'food', 'filled', 'green', 'vegetables', 'bananas', 'purple', 'old', 'station', 'colored', 'sitting', 'beside', 'road', 'surfboard', 'top', 'side', 'next', 'silver', 'riding', 'group', 'motorcycle', 'driving', 'past', 'buildings', 'people', 'cat', 'water', 'head', 'man', 'another', 'ocean', 'older', 'beach', 'day', 'person', 'one', 'sits', 'cow', 'ground', 'horse', 'guy', 'floor', 'lot', 'line', 'set', 'lined', 'row', 'dish', 'table', 'bowl', 'getting', 'drink', 'boy', 'young', 'face', 'close', 'holding', 'skateboard', 'field', 'grass', 'skate', 'board', 'child', 'skateboarder', 'edge', 'mirror', 'high', 'jet', 'clear', 'brown', 'middle', 'eating', 'horses', 'near', 'standing', 'building', 'eat', 'woman', 'park', 'laying', 'half', 'cake', 'plate', 'pink', 'seat', 'desk', 'laptop', 'computer', 'corner', 'window', 'hanging', 'ride', 'back', 'house', 'walking', 'dog', 'fence', 'flowers', 'walks', 'girl', 'public', 'kids', 'stands', 'playing', 'three', 'bus', 'rides', 'going', 'dining', 'wooden', 'bright', 'lights', 'shown', 'beautiful', 'wood', 'traffic', 'intersection', 'umbrella', 'scene', 'night', 'covered', 'stop', 'light', 'airport', 'runway', 'giraffe', 'sit', 'waiting', 'crowd', 'ready', 'train', 'stand', 'ramp', 'display', 'photo', 'skiing', 'snow', 'cross', 'skis', 'forest', 'view', 'smiling', 'coming', 'bunch', 'men', 'female', 'preparing', 'carrying', 'photograph', 'sheep', 'animals', 'surrounded', 'shot', 'leaning', 'river', 'paper', 'clean', 'like', 'double', 'underneath', 'fire', 'living', 'lit', 'tv', 'brick', 'television', 'sign', 'restaurant', 'outside', 'store', 'background', 'cutting', 'looks', 'lake', 'truck', 'women', 'around', 'working', 'dirt', 'signs', 'big', 'screen', 'jumping', 'stopped', 'sun', 'setting', 'different', 'together', 'meal', 'way', 'hot', 'piece', 'lady', 'traveling', 'bed', 'talking', 'children', 'play', 'toy', 'phone', 'hat', 'teddy', 'bear', 'fruit', 'yellow', 'surface', 'showing', 'keyboard', 'elephants', 'trees', 'shows', 'track', 'orange', 'image', 'posing', 'slope', 'ski', 'wearing', 'mountain', 'trick', 'pizza', 'hands', 'camera', 'towards', 'resting', 'coffee', 'grassy', 'hill', 'moving', 'cows', 'herd', 'walk', 'grazing', 'shirt', 'stuffed', 'chair', 'sunny', 'seen', 'stone', 'cell', 'lying', 'frisbee', 'someone', 'tree', 'male', 'remote', 'adult', 'bag', 'hand', 'oven', 'pulling', 'dark', 'onto', 'snowy', 'making', 'skiers', 'pair', 'glass', 'tie', 'chairs', 'kite', 'body', 'giraffes', 'something', 'couch', 'furniture', 'holds', 'look', 'watching', 'displayed', 'tall', 'tower', 'watch', 'attached', 'zebras', 'animal', 'elephant', 'placed', 'jacket', 'lots', 'grey', 'vase', 'dressed', 'sleeping', 'plates', 'glasses', 'using', 'pole', 'trying', 'suit', 'made', 'tracks', 'passing', 'time', 'outdoor', 'nice', 'cup', 'bedroom', 'running', 'hydrant', 'pile', 'cut', 'zebra', 'zoo', 'hitting', 'surfer', 'sand', 'number', 'kid', 'bread', 'luggage', 'video', 'meat', 'cheese', 'game', 'bird', 'enclosure', 'baseball', 'boys', 'hit', 'lush', 'surfing', 'tennis', 'broccoli', 'ball', 'player', 'wine', 'sandwich', 'topped', 'racket', 'swinging', 'surf', 'slice', 'batter', 'skier', 'umbrellas', 'snowboard', 'mouth', 'wave', 'tray', 'court', 'racquet', 'wii', 'waves', 'players', 'bat', 'swing']\n",
      "loading annotations into memory...\n",
      "Done (t=0.32s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "id2objs, id2words, word2ids = get_maps('train', verbose = True)\n",
    "\n",
    "id2objs_val, id2words_val, word2ids_val = get_maps('val')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_obj_counts(img_ids):\n",
    "    out = {}\n",
    "    num_imgs = len(img_ids)\n",
    "    for img_id in img_ids:\n",
    "        objs = id2objs[img_id]\n",
    "        for obj in objs:\n",
    "            if obj not in out:\n",
    "                out[obj] = 0\n",
    "            out[obj] += 1 / num_imgs\n",
    "    return out\n",
    "\n",
    "def compare_words(word1, word2, word2ids):\n",
    "    \n",
    "    counts1 = get_obj_counts(word2ids[word1])\n",
    "    counts2 = get_obj_counts(word2ids[word2])\n",
    "    \n",
    "    k1 = [key for key in counts1]\n",
    "    k2 = [key for key in counts2]\n",
    "    \n",
    "    keys = list(set(k1).union(set(k2)))\n",
    "    \n",
    "    diff = {}\n",
    "    for key in keys:\n",
    "        if key in counts1:\n",
    "            v1 = counts1[key]\n",
    "        else:\n",
    "            v1 = 0.0\n",
    "        \n",
    "        if key in counts2:\n",
    "            v2 = counts2[key]\n",
    "        else:\n",
    "            v2 = 0.0\n",
    "        \n",
    "        diff[key] = v1 - v2\n",
    "        \n",
    "    diff_sorted = sorted(diff.items(), key = lambda x: np.abs(x[1]), reverse = True)\n",
    "        \n",
    "    return diff_sorted\n",
    "\n",
    "def get_splits(label1, label2, spurious, word2ids, id2objs):\n",
    "    ids1 = word2ids[label1]\n",
    "    ids2 = word2ids[label2]\n",
    "\n",
    "    just1 = np.setdiff1d(ids1, ids2)\n",
    "    just2 = np.setdiff1d(ids2, ids1)\n",
    "   \n",
    "    splits = {}\n",
    "    splits['1s'] = [] # Answer is 1 (eg, label 1) and Spurious is present\n",
    "    splits['1ns'] = [] # Answer is 1 and no Spurious\n",
    "    splits['0s'] = [] # Answer is 0 (eg, label 2) and Spurious\n",
    "    splits['0ns'] = [] # Answer is 0 and no Spurious\n",
    "    \n",
    "    for img_id in just1:\n",
    "        if spurious in id2objs[img_id]:\n",
    "            splits['1s'].append(str(img_id))\n",
    "        else:\n",
    "            splits['1ns'].append(str(img_id))\n",
    "    \n",
    "    \n",
    "    for img_id in just2:\n",
    "        if spurious in id2objs[img_id]:\n",
    "            splits['0s'].append(str(img_id))\n",
    "        else:\n",
    "            splits['0ns'].append(str(img_id))\n",
    "            \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('airplane', 0.984017654083118), ('car', -0.3438270646869643), ('person', -0.285584405587939), ('traffic light', -0.24937485988238162), ('bus', -0.17644913683344116), ('truck', 0.13954683703286622), ('handbag', -0.13596361169261262), ('motorcycle', -0.12464757660148773), ('bicycle', -0.11915601772811545), ('stop sign', -0.08854591882873832)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# cloudy, sunny, snowy\n",
    "# mountain, field, beach, river\n",
    "# runway/airport, street\n",
    "# kitchen, bathroom\n",
    "\n",
    "label1 = 'runway'\n",
    "label2 = 'street'\n",
    "\n",
    "print(compare_words(label1, label2, word2ids)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sizes\n",
      "1s 1120\n",
      "1ns 14\n",
      "0s 33\n",
      "0ns 12510\n",
      "\n",
      "Val Sizes\n",
      "1s 34\n",
      "1ns 2\n",
      "0s 2\n",
      "0ns 537\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "spurious = 'airplane'\n",
    "\n",
    "mkdir = True\n",
    "\n",
    "if mkdir:\n",
    "    out_dir = '{}/{}-{}/{}'.format(get_data_dir(), label1, label2, spurious)\n",
    "    os.system('rm -rf {}'.format(out_dir))\n",
    "    Path(out_dir).mkdir(parents = True, exist_ok = True)\n",
    "    os.system('mkdir {}/train'.format(out_dir))\n",
    "    os.system('mkdir {}/val'.format(out_dir))\n",
    "\n",
    "print('Train Sizes')\n",
    "splits = get_splits(label1, label2, spurious, word2ids, id2objs)\n",
    "for key in splits:\n",
    "    print(key, len(splits[key]))\n",
    "print()\n",
    "\n",
    "if mkdir:\n",
    "    with open('{}/train/splits.json'.format(out_dir), 'w') as f:\n",
    "        json.dump(splits, f)\n",
    "    \n",
    " \n",
    "print('Val Sizes')\n",
    "splits = get_splits(label1, label2, spurious, word2ids_val, id2objs_val)\n",
    "for key in splits:\n",
    "    print(key, len(splits[key]))\n",
    "\n",
    "if mkdir:\n",
    "    with open('{}/val/splits.json'.format(out_dir), 'w') as f:\n",
    "        json.dump(splits, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:countervision]",
   "language": "python",
   "name": "conda-env-countervision-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

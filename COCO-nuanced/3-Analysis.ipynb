{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1='runway'\n",
    "label2='street'\n",
    "spurious='airplane'\n",
    "main_dir = './2-Models/Models/{}-{}/{}'.format(label1, label2, spurious)\n",
    "\n",
    "MODES = {'initial-tune': 'Baseline', 'combined-transfer-ptune': 'SPIRE', 'fs-tune-ptune': 'FS', 'added-transfer-ptune': 'Adding Only', 'removed-transfer-ptune': 'Removing Only'}\n",
    "    \n",
    "# Collect the data for each training mode\n",
    "data = {}\n",
    "for mode_dir in glob.glob('{}/*'.format(main_dir)):\n",
    "    mode = mode_dir.split('/')[-1]\n",
    "\n",
    "    # Aggregate the data for that mode across the trials\n",
    "    data_mode = {}\n",
    "    count = 0\n",
    "    for trial_dir in glob.glob('{}/trial*'.format(mode_dir)):\n",
    "        # Include both Accuracy and Search results\n",
    "        for file in ['results.json', 'counterfactual.json']:\n",
    "            try:\n",
    "                with open('{}/{}'.format(trial_dir, file), 'r') as f:\n",
    "                    data_tmp = json.load(f)\n",
    "                for key in data_tmp:\n",
    "                    if key in data_mode:\n",
    "                        data_mode[key].append(data_tmp[key])\n",
    "                    else:\n",
    "                        data_mode[key] = [data_tmp[key]]\n",
    "            except:\n",
    "                pass\n",
    "    # We want the average\n",
    "    for key in data_mode:\n",
    "        data_tmp = data_mode[key]\n",
    "        data_mode[key] = '{} ({})'.format(np.round(np.mean(data_tmp), 3), np.round(np.std(data_tmp), 3))\n",
    "\n",
    "    data[mode] = data_mode\n",
    "\n",
    "# Convert the nested dictionary into a csv\n",
    "modes = [key for key in data]\n",
    "modes.sort()\n",
    "metrics = [key for key in data[modes[0]]]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Mode'] = modes\n",
    "for metric in metrics:\n",
    "    data_tmp = []\n",
    "    for mode in modes:\n",
    "        data_tmp.append(data[mode][metric])\n",
    "    df[metric] = data_tmp\n",
    "\n",
    "\n",
    "df = df.set_index('Mode')\n",
    "df = df.reindex(list(MODES))\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.replace(MODES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Original data\n",
      "          Mode             1s            0ns\n",
      "      Baseline  0.956 (0.036)  0.998 (0.002)\n",
      "         SPIRE  0.805 (0.045)  0.998 (0.002)\n",
      "            FS  0.926 (0.047)  0.998 (0.001)\n",
      "   Adding Only  0.796 (0.057)  0.999 (0.001)\n",
      " Removing Only  0.956 (0.023)  0.997 (0.001)\n",
      "\n",
      "\n",
      "Accuracy on External data\n",
      "          Mode           c-1s          c-1ns           c-0s      c-0ns\n",
      "      Baseline  0.908 (0.065)  0.483 (0.145)   0.752 (0.08)  1.0 (0.0)\n",
      "         SPIRE  0.723 (0.048)  0.756 (0.105)  0.958 (0.036)  1.0 (0.0)\n",
      "            FS  0.871 (0.056)  0.502 (0.139)  0.758 (0.077)  1.0 (0.0)\n",
      "   Adding Only  0.675 (0.036)  0.469 (0.108)  0.956 (0.033)  1.0 (0.0)\n",
      " Removing Only  0.935 (0.045)  0.833 (0.068)  0.712 (0.071)  1.0 (0.0)\n",
      "\n",
      "\n",
      "Metrics on External data\n",
      "          Mode         c-r-gap        c-h-gap            c-p\n",
      "      Baseline   0.425 (0.138)   0.248 (0.08)  0.286 (0.062)\n",
      "         SPIRE  -0.033 (0.083)  0.042 (0.036)  0.746 (0.175)\n",
      "            FS   0.369 (0.125)  0.242 (0.077)  0.288 (0.065)\n",
      "   Adding Only   0.206 (0.093)  0.044 (0.033)  0.691 (0.198)\n",
      " Removing Only   0.102 (0.071)  0.288 (0.071)  0.299 (0.046)\n",
      "\n",
      "\n",
      "Counterfactual Evaluation\n",
      "          Mode 1s-spurious/box 1s-spurious/pixel-paint   0ns+spurious\n",
      "      Baseline   0.526 (0.137)           0.426 (0.083)  0.079 (0.017)\n",
      "         SPIRE    0.14 (0.059)           0.222 (0.078)  0.004 (0.003)\n",
      "            FS   0.517 (0.129)           0.414 (0.063)  0.064 (0.022)\n",
      "   Adding Only   0.388 (0.071)           0.377 (0.043)  0.004 (0.002)\n",
      " Removing Only   0.088 (0.054)           0.241 (0.071)  0.064 (0.012)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Accuracy on Original data')\n",
    "print(df[['Mode', '1s', '0ns']].to_string(index = False))\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Accuracy on External data')\n",
    "print(df[['Mode', 'c-1s', 'c-1ns', 'c-0s', 'c-0ns']].to_string(index = False))\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Metrics on External data')\n",
    "print(df[['Mode', 'c-r-gap', 'c-h-gap', 'c-p']].to_string(index = False))\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Counterfactual Evaluation')\n",
    "print(df[['Mode', '1s-spurious/box', '1s-spurious/pixel-paint', '0ns+spurious']].to_string(index = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:countervision]",
   "language": "python",
   "name": "conda-env-countervision-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "TRANSFER = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cs230.stanford.edu/blog/datapipeline/\n",
    "\n",
    "# Create a list of filenames and labels for the dataset\n",
    "def create_pairs(location = '/home/gregory/Datasets/COCO/2017', mode = 'val'):\n",
    "    \n",
    "    # Each 'label' vector is large enough for easy indexing, but this means it contains unused indices\n",
    "    dim = 91\n",
    "    \n",
    "    file = '{}/annotations/instances_{}2017.json'.format(location, mode)\n",
    "    \n",
    "    coco = COCO(file)\n",
    "    \n",
    "    images = coco.loadImgs(coco.getImgIds())\n",
    "    \n",
    "    filenames = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "    \n",
    "        im_obj = images[i]\n",
    "        \n",
    "        filenames.append('{}/{}2017/{}'.format(location, mode, im_obj['file_name']))\n",
    "        \n",
    "        annotations = coco.loadAnns(coco.getAnnIds(im_obj['id'], iscrowd=None))\n",
    "        label = np.zeros((dim), dtype = np.float32)\n",
    "        for x in annotations:\n",
    "            label[x['category_id']] = 1.0\n",
    "        labels.append(label)\n",
    "        \n",
    "    filenames = np.array(filenames)\n",
    "    labels = np.array(labels)\n",
    "        \n",
    "    return filenames, labels\n",
    "    \n",
    "def parse_function(filename, label):\n",
    "    image_string = tf.io.read_file(filename)\n",
    "\n",
    "    #Don't use tf.image.decode_image, or the output shape will be undefined\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "\n",
    "    #This will convert to float values in [0, 1]\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    image = tf.image.resize_with_pad(image, 224, 224)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def create_dataset(filenames, labels, batch_size = 32, num_parallel_calls = 4):\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.shuffle(len(filenames))\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=num_parallel_calls)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(1)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Model) (None, 1280)              2257984   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 91)                116571    \n",
      "=================================================================\n",
      "Total params: 2,374,555\n",
      "Trainable params: 116,571\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained model\n",
    "\n",
    "model_base = tf.keras.applications.MobileNetV2(input_shape = (224, 224, 3),\n",
    "                                               include_top=False,\n",
    "                                               pooling = 'avg',\n",
    "                                               weights='imagenet') #ResNet50\n",
    "model_base.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  model_base,\n",
    "  tf.keras.layers.Dense(91)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=9.05s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3697it [09:56,  6.20it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch / Epoch Train Loss / Val Loss: 0 0.07064531 0.06640391 -> saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3697it [09:55,  6.20it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch / Epoch Train Loss / Val Loss: 1 0.063702784 0.06566886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3697it [09:55,  6.21it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch / Epoch Train Loss / Val Loss: 2 0.062279277 0.06631933\n",
      "Dropping learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3697it [09:23,  6.56it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch / Epoch Train Loss / Val Loss: 3 0.05833921 0.06351866 -> saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3697it [09:23,  6.56it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch / Epoch Train Loss / Val Loss: 4 0.05789144 0.06368582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3697it [09:24,  6.54it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch / Epoch Train Loss / Val Loss: 5 0.05771087 0.06376489\n",
      "Dropping learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3697it [09:23,  6.57it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch / Epoch Train Loss / Val Loss: 6 0.056496873 0.06330037\n",
      "Dropping learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3697it [09:25,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch / Epoch Train Loss / Val Loss: 7 0.056047935 0.063010454\n"
     ]
    }
   ],
   "source": [
    "model_location = './model_transfer/weights.h5'\n",
    "\n",
    "if TRANSFER: \n",
    "    learning_rate = 0.001\n",
    "    learning_rate_decay = 0.3\n",
    "    learning_rate_drops = 3\n",
    "    min_epochs = 2\n",
    "    stopping_epochs = 2\n",
    "    stopping_tol = 0.001\n",
    "    batch_size = 32\n",
    "\n",
    "    folder = '/home/gregory/Datasets/COCO/2017'\n",
    "\n",
    "    f, l = create_pairs(mode = 'train')\n",
    "    n_train = len(f)\n",
    "\n",
    "    data_train = create_dataset(f, l, batch_size = batch_size)\n",
    "\n",
    "    f, l = create_pairs(mode = 'val')\n",
    "    n_val = len(f)\n",
    "\n",
    "    data_val = create_dataset(f, l, batch_size = batch_size)\n",
    "\n",
    "    n_batches_train = math.floor(n_train / batch_size)\n",
    "    n_batches_val = math.floor(n_val / batch_size)\n",
    "\n",
    "    def loss(model, inputs, targets):\n",
    "        preds = model(inputs)\n",
    "        return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = targets, logits = preds))\n",
    "\n",
    "    def grad(model, inputs, targets):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = loss(model, inputs, targets)\n",
    "        return loss_value, tape.gradient(loss_value, model.trainable_variables)\n",
    "\n",
    "    # Setup the initial optimizer (it will be re-initialized when the learning rate gets dropped)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "\n",
    "    # Basic counters for the training process\n",
    "    epoch = 0\n",
    "    best_epoch = 0\n",
    "    best_loss = np.inf\n",
    "    drops = 0\n",
    "\n",
    "    # Run the training loop\n",
    "    while True:\n",
    "\n",
    "        # Check the stopping condition\n",
    "        if epoch - best_epoch > stopping_epochs and epoch > min_epochs:\n",
    "            # We have finished only if we have fully decayed the learning_rate\n",
    "            if drops == learning_rate_drops:\n",
    "                break\n",
    "            else:\n",
    "                print(\"Dropping learning_rate\")\n",
    "                learning_rate *= learning_rate_decay\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "                drops += 1\n",
    "\n",
    "        # Train for an epoch\n",
    "        epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "        for (x_batch, y_batch) in tqdm(data_train):\n",
    "            loss_value, grads = grad(model, x_batch, y_batch)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            epoch_loss_avg.update_state(loss_value)\n",
    "        epoch_loss = epoch_loss_avg.result().numpy()\n",
    "\n",
    "        # Calculate the validation loss\n",
    "        epoch_loss_avg_val = tf.keras.metrics.Mean()\n",
    "        for (x_batch, y_batch) in data_val:\n",
    "            loss_value = loss(model, x_batch, y_batch)\n",
    "            epoch_loss_avg_val.update_state(loss_value)\n",
    "        value = epoch_loss_avg_val.result().numpy()\n",
    "\n",
    "        # Check if we have made progress\n",
    "        if value < best_loss - stopping_tol:\n",
    "            print(\"Epoch / Epoch Train Loss / Val Loss: \" + str(epoch) + \" \" + str(epoch_loss) + \" \" + str(value) + \" -> saving\")\n",
    "            best_loss = value\n",
    "            best_epoch = epoch\n",
    "            model.save_weights(model_location)\n",
    "        else:\n",
    "            print(\"Epoch / Epoch Train Loss / Val Loss: \" + str(epoch) + \" \" + str(epoch_loss) + \" \" + str(value))\n",
    "\n",
    "        # Update counters\n",
    "        epoch += 1\n",
    "        \n",
    "model.load_weights(model_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.36s)\n",
      "creating index...\n",
      "index created!\n",
      "Per Object Validation Accuracy:  [1.     0.863  0.9746 0.9132 0.9816 0.9922 0.9782 0.988  0.9548 0.9862\n",
      " 0.9728 0.988  1.     0.9912 0.994  0.9578 0.9832 0.9832 0.9764 0.9834\n",
      " 0.9908 0.9876 0.9944 0.9962 0.9968 0.9952 1.     0.955  0.9754 1.\n",
      " 1.     0.9438 0.9808 0.981  0.9874 0.9894 0.9892 0.9738 0.9908 0.9896\n",
      " 0.9908 0.9856 0.9892 0.9898 0.9298 1.     0.9788 0.9248 0.9726 0.9624\n",
      " 0.9686 0.9496 0.9832 0.9852 0.9816 0.9878 0.9924 0.9866 0.9924 0.9842\n",
      " 0.9898 0.9806 0.9012 0.9678 0.9672 0.9796 1.     0.9242 1.     1.\n",
      " 0.9852 1.     0.97   0.9744 0.9896 0.9736 0.9864 0.961  0.9892 0.983\n",
      " 0.9984 0.98   0.983  1.     0.9582 0.9748 0.9776 0.9954 0.991  0.9982\n",
      " 0.9932]\n",
      "Average Validation Accuracy 0.978978021978022\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "f, l = create_pairs(mode = 'val')\n",
    "n_val = len(f)\n",
    "\n",
    "data_val = create_dataset(f, l, batch_size = batch_size)\n",
    "\n",
    "n_batches_val = math.ceil(n_val / batch_size)\n",
    "\n",
    "counts = []\n",
    "\n",
    "for (x_batch, y_batch) in data_val:\n",
    "    \n",
    "    y_hat_batch = 1.0 * (tf.math.sigmoid(model(x_batch)).numpy() >= 0.5)\n",
    "    \n",
    "    counts_batch = np.sum(1.0 * (y_hat_batch == y_batch.numpy()), axis = 0)\n",
    "    \n",
    "    counts.append(counts_batch)\n",
    "    \n",
    "acc = np.sum(np.array(counts), axis = 0) / n_val\n",
    "    \n",
    "print(\"Per Object Validation Accuracy: \", acc)\n",
    "print(\"Average Validation Accuracy\", np.mean(acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:countervision]",
   "language": "python",
   "name": "conda-env-countervision-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

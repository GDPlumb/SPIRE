{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ded3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics import average_precision_score\n",
    "from scipy import stats\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../Common/')\n",
    "from COCOWrapper import COCOWrapper\n",
    "from Dataset import ImageDataset, my_dataloader\n",
    "from ModelWrapper import ModelWrapper\n",
    "from ResNet import get_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffb4cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/gregory/Datasets/SpatialSense'\n",
    "\n",
    "modes = {'initial-tune': 'Baseline', 'spire': 'SPIRE', 'fs-3': 'FS'}\n",
    "trials = [0,1,2,3,4,5,6,7]\n",
    "\n",
    "baseline = 'initial-tune'\n",
    "corrected_list = ['spire', 'fs-3']\n",
    "\n",
    "with open('{}/annotations.json'.format(data_dir), 'r') as f:\n",
    "    anns = json.load(f)\n",
    "\n",
    "coco = COCOWrapper(mode = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "121966fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image labels and locations for SpatialSense\n",
    "files = []\n",
    "label_dict = defaultdict(list)\n",
    "\n",
    "def get_info(x):\n",
    "    # Get the file location\n",
    "    url = x['url']\n",
    "    if 'flickr' in url:\n",
    "        source = 'flickr'\n",
    "    else:\n",
    "        source = 'nyu'\n",
    "    filename = url.split('/')[-1]\n",
    "    location = '{}/images/{}/{}'.format(data_dir, source, filename)\n",
    "    # Get the objects in the image\n",
    "    anns = x['annotations']\n",
    "    labels = []\n",
    "    for ann in anns:\n",
    "        labels.append(ann['object']['name'])\n",
    "        labels.append(ann['subject']['name'])\n",
    "    labels = list(set(labels))    \n",
    "    return location, labels\n",
    "\n",
    "for x in anns:\n",
    "    loc, labs = get_info(x)\n",
    "    files.append(loc)\n",
    "    for lab in labs:\n",
    "        label_dict[lab].append(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "832c8a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bench', 'truck', 'dog', 'couch', 'knife', 'fork', 'spoon', 'bird', 'bowl']\n"
     ]
    }
   ],
   "source": [
    "# Find the common objects that SPIRE identified as 'main' for some SP\n",
    "with open('./2-Models/HPS/spire/spire.json', 'r') as f:\n",
    "    mains = json.load(f)\n",
    "\n",
    "tmp = []\n",
    "for main in mains:\n",
    "    tmp.append(main.replace('+', ' '))\n",
    "    \n",
    "mains = tmp\n",
    "\n",
    "tmp = []\n",
    "for main in mains:\n",
    "    if len(label_dict[main]) >= 50:\n",
    "        tmp.append(main)\n",
    "        \n",
    "mains = tmp\n",
    "print(mains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b43af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the labels\n",
    "y = []\n",
    "for file in files:\n",
    "    y_tmp = np.zeros((91))\n",
    "    for main in mains:\n",
    "        index = coco.get_class_id(main)\n",
    "        if file in label_dict[main]:\n",
    "            y_tmp[index] = 1\n",
    "    y.append(y_tmp)\n",
    "\n",
    "# Get the model's predictions\n",
    "out = {}\n",
    "for mode in modes:\n",
    "    out_mode = defaultdict(list)\n",
    "    for trial in trials:  \n",
    "        model_dir = './2-Models/Models/{}/trial{}/model.pt'.format(mode, trial)\n",
    "\n",
    "        model, _ = get_model(mode = 'tune', parent = model_dir, out_features = 91)\n",
    "        model.eval()\n",
    "        model.cuda()\n",
    "\n",
    "        wrapper = ModelWrapper(model)\n",
    "\n",
    "        dataset = ImageDataset(files, y)\n",
    "        dataloader = my_dataloader(dataset)\n",
    "        y_hat, y_true = wrapper.predict_dataset(dataloader)\n",
    "        \n",
    "        for main in mains:\n",
    "            index = coco.get_class_id(main)\n",
    "            v = average_precision_score(y_true[:, index], y_hat[:, index])\n",
    "            out_mode[main].append(v)\n",
    "    out[mode] = out_mode    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c86d97a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per object\n",
      "\n",
      "Object:  bench\n",
      "Baseline 0.091 0.0174\n",
      "SPIRE 0.093 0.0154\n",
      "FS 0.086 0.022\n",
      "\n",
      "Object:  truck\n",
      "Baseline 0.262 0.0222\n",
      "SPIRE 0.28 0.0137\n",
      "FS 0.254 0.0176\n",
      "\n",
      "Object:  dog\n",
      "Baseline 0.471 0.0218\n",
      "SPIRE 0.462 0.0195\n",
      "FS 0.441 0.0193\n",
      "\n",
      "Object:  couch\n",
      "Baseline 0.192 0.0067\n",
      "SPIRE 0.198 0.0118\n",
      "FS 0.175 0.0101\n",
      "\n",
      "Object:  knife\n",
      "Baseline 0.129 0.0215\n",
      "SPIRE 0.139 0.0126\n",
      "FS 0.074 0.0184\n",
      "\n",
      "Object:  fork\n",
      "Baseline 0.127 0.0099\n",
      "SPIRE 0.134 0.008\n",
      "FS 0.12 0.0156\n",
      "\n",
      "Object:  spoon\n",
      "Baseline 0.106 0.0113\n",
      "SPIRE 0.109 0.0148\n",
      "FS 0.108 0.0162\n",
      "\n",
      "Object:  bird\n",
      "Baseline 0.286 0.0253\n",
      "SPIRE 0.278 0.0213\n",
      "FS 0.273 0.0262\n",
      "\n",
      "Object:  bowl\n",
      "Baseline 0.166 0.0145\n",
      "SPIRE 0.173 0.0098\n",
      "FS 0.147 0.0135\n",
      "\n",
      "\n",
      "Aggregated results\n",
      "\n",
      "Baseline 0.203\n",
      "SPIRE 0.207\n",
      "FS 0.186\n",
      "\n",
      "\n",
      "Stat testing on the differences\n",
      "\n",
      "SPIRE\n",
      "0.004 0.0049 0.0722\n",
      "FS\n",
      "-0.0169 0.0026 0.0\n"
     ]
    }
   ],
   "source": [
    "# Get results\n",
    "print('Results per object')\n",
    "for main in mains:\n",
    "    print()\n",
    "    print('Object: ', main)\n",
    "    for mode in modes:\n",
    "        v = out[mode][main]\n",
    "        print(modes[mode], np.round(np.mean(v), 3), np.round(np.std(v), 4))\n",
    "        \n",
    "print()\n",
    "print()\n",
    "print('Aggregated results')\n",
    "print()\n",
    "\n",
    "for mode in modes:\n",
    "    tmp = []\n",
    "    for main in mains:\n",
    "        tmp.append(np.mean(out[mode][main]))\n",
    "    print(modes[mode], np.round(np.mean(tmp), 3))\n",
    " \n",
    "\n",
    "print()\n",
    "print()\n",
    "print('Stat testing on the differences')\n",
    "print()\n",
    "\n",
    "agg = {}\n",
    "for mode in modes:\n",
    "    avg = np.zeros((len(trials)))\n",
    "    for main in mains:\n",
    "        avg += np.array(out[mode][main])\n",
    "    avg /= len(mains)\n",
    "    agg[mode] = avg\n",
    "\n",
    "for corrected in corrected_list:\n",
    "    print(modes[corrected])\n",
    "    diff = agg[corrected] - agg[baseline]\n",
    "    test = stats.ttest_rel(agg[corrected], agg[baseline])\n",
    "    print(np.round(np.mean(diff), 4), np.round(np.std(diff), 4), np.round(test.pvalue, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7048fd15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:countervision]",
   "language": "python",
   "name": "conda-env-countervision-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
